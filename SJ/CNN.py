# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gnzejrTsXwx71NewR1bArcmmAld8QC6b
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.autograd import Variable
from six.moves import urllib

batch_size = 64


opener = urllib.request.build_opener()
opener.addheaders = [('User-agent', 'Mozilla/5.0')]
urllib.request.install_opener(opener)



train_dataset = datasets.MNIST(root = './data/', train = True, transform = transforms.ToTensor(),download = True)
test_dataset = datasets.MNIST(root = './data/', train = False, transform = transforms.ToTensor(), download = True)

train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size = batch_size, shuffle = True)
test_loader = torch.utils.data.DataLoader(dataset= test_dataset, batch_size = batch_size, shuffle = False)

class Net(nn.Module):
  def __init__(self):
    super(Net, self).__init__()
    self.conv1 = nn.Conv2d(1, 10, kernel_size = 5) # 5x5 weight가 10개 생성
    self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)
    self.mp = nn.MaxPool2d(2)
    self.fc = nn.Linear(320, 10)#fully connectec
  def forward(self, x):
    in_size = x.size(0)
    x = F.relu(self.mp(self.conv1(x)))
    x = F.relu(self.mp(self.conv2(x)))
    x = x.view(in_size, -1) # flatten the tensor : Matrix -> Vector
    x = self.fc(x)
    return F.log_softmax(x)

model = Net()

optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)

def train(epoch):
  model.train()
  for batch_idx, (data, target) in enumerate(train_loader):
    data, target = Variable(data), Variable(target)
    optimizer.zero_grad()
    output = model(data)
    loss = F.nll_loss(output, target)
    loss.backward()
    optimizer.step()
    if batch_idx % 10 == 0:
      print('Train Epoch : {} [{}/{} ({:.0f}%)]\t Loss: {:.6f}'.format(epoch, batch_idx*len(data), len(train_loader.dataset), 100.*batch_idx/len(train_loader), loss.item()))


def test():
  model.eval()
  test_loss = 0
  correct = 0
  for data, target in test_loader:
    data, target = Variable(data, volatile = True), Variable(target)
    output = model(data)
  
    test_loss += F.nll_loss(output, target, size_average = False).data
    pred = output.data.max(1, keepdim = True)[1]
    correct += pred.eq(target.data.view_as(pred)).cpu().sum()

  test_loss /= len(test_loader.dataset)

  print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))

for epoch in range(1, 10):
  train(epoch)
  test()

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.autograd import Variable
from six.moves import urllib

batch_size = 64


opener = urllib.request.build_opener()
opener.addheaders = [('User-agent', 'Mozilla/5.0')]
urllib.request.install_opener(opener)

device = 'cuda' if torch.cuda.is_available() else 'cpu'

train_dataset = datasets.MNIST(root = './data/', train = True, transform = transforms.ToTensor(), download = True)
test_dataset = datasets.MNIST(root = './data/', train = False, transform = transforms.ToTensor(), download = True)

train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)
test_loader = torch.utils.data.DataLoader(dataset=  test_dataset, batch_size = batch_size, shuffle = False)

class InceptionA(nn.Module):
  def __init__(self, in_channels):
    super(InceptionA, self).__init__()
    self.branchx1 = nn.Conv2d(in_channels, 16, kernel_size = 1) # 1X1 Convolution

    self.branch_pool = nn.Conv2d(in_channels, 24, kernel_size = 1)

    self.branch5x5_1 = nn.Conv2d(in_channels, 16, kernel_size = 1)
    self.branch5x5_2 = nn.Conv2d(16, 24, kernel_size = 5, padding = 2)

    self.branch3x3dbl_1 = nn.Conv2d(in_channels, 16, kernel_size = 1)
    self.branch3x3dbl_2 = nn.Conv2d(16, 24, kernel_size = 3, padding = 1)
    self.branch3x3dbl_3 = nn.Conv2d(24, 24, kernel_size = 3, padding = 1)

  def forward(self, x):
    branch1x1 = self.branchx1(x)

    branch_pool = F.avg_pool2d(x, kernel_size = 3, stride = 1, padding = 1)
    branch_pool = self.branch_pool(branch_pool)

    branch_5x5 = self.branch5x5_1(x)
    branch_5x5 = self.branch5x5_2(branch_5x5)

    branch_3x3dbl = self.branch3x3dbl_1(x)
    branch_3x3dbl = self.branch3x3dbl_2(branch_3x3dbl)
    branch_3x3dbl = self.branch3x3dbl_3(branch_3x3dbl)

    outputs = [branch1x1, branch_5x5, branch_3x3dbl, branch_pool]
    return torch.cat(outputs, 1)

class Net(nn.Module):
  def __init__(self):
    super(Net, self).__init__()
    self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)
    self.conv2 = nn.Conv2d(88, 20, kernel_size = 5)

    self.incept1 = InceptionA(in_channels = 10)
    self.incept2 = InceptionA(in_channels = 20)

    self.mp = nn.MaxPool2d(2)
    self.fc = nn.Linear(1408, 10)
  
  def forward(self, x):
    in_size = x.size(0)
    x = F.relu(self.mp(self.conv1(x)))
    x = self.incept1(x)
    x = F.relu(self.mp(self.conv2(x)))
    x = self.incept2(x)
    x = x.view(in_size, -1)
    x = self.fc(x)

    return F.log_softmax(x)

model = Net()
model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)

def train(epoch):
  model.train()
  for batch_idx, (data, target) in enumerate(train_loader):
    data, target = data.to(device), target.to(device)
    optimizer.zero_grad()
    output = model(data)
    loss = criterion(output, target)
    loss.backward()
    optimizer.step()

    if batch_idx % 10 == 0:
      print('Train Epoch : {} | Batch Status : {}/{} ({:.0f}%) | Loss : ({:.6f})'.format(epoch, batch_idx*len(data)
              ,len(train_loader.dataset), 100.*batch_idx/len(train_loader), loss.item()))

def test():
  model.eval()
  test_loss = 0
  correct = 0
  for data, target in test_loader:
    data, target = data.to(device), target.to(device)
    output = model(data)
    test_loss += criterion(output, target)
    pred = output.data.max(1, keepdim = True)[1]
    correct += pred.eq(target.data.view_as(pred)).cpu().sum()
  
  test_loss /= len(test_loader.dataset)
  
  print(f'\n==============================\nTest set: Average loss: {test_loss:.4f}, Accuracy : {correct}/{len(test_loader.dataset)}'
        f'({100.*correct/len(test_loader.dataset):.0f}%)')

for epoch in range(1, 10):
    train(epoch)
    test()

